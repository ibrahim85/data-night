{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим данные\n",
    " * При первом запуске скачаем train.csv и evaluation.csv\n",
    " * При повторных запусках файлы уже будут на месте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = data.loc[data['cancel_time']<5000]\n",
    "X = data[data.columns[:len(data.columns)-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = data['burned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(X[X['cancel_time']<0])*1./len(X)\n",
    "# X = X.loc[X['cancel_time']<500]\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# X_notminusone = X.loc[X['cancel_time']!=-1]\n",
    "# trsh = plt.hist(np.log(np.array([1.]*len(X_notminusone)) + X_notminusone['cancel_time'].values), bins=2000)\n",
    "# plt.xlim(0., 7.)\n",
    "# plt.ylim(0., 3000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 8))\n",
    "# trash = plt.hist( data.loc[(data['burned']==1) & (data['cancel_time']<100000)]['cancel_time'], bins=1000 )\n",
    "# plt.ylim(0, 5000)\n",
    "# plt.xlim(0, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.loc[(data['burned']==0)]['cancel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.loc[(data['burned']==1)]['cancel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# citycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!!!!!\n",
    "# X = pd.DataFrame.from_csv(\"./train_with_cityid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = [\n",
    "    [55.754216, 37.61343],  #0\n",
    "    [51.661535, 39.200287], #1\n",
    "    [56.326887, 44.005986], #2\n",
    "    [55.798551, 49.106324], #3\n",
    "    [59.939095, 30.315868]  #4\n",
    "]\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "minminmin = 10**15\n",
    "\n",
    "def city_id(coords):\n",
    "    mn = 0\n",
    "    min_value = minminmin\n",
    "    for i in range(len(centers)):\n",
    "        \n",
    "        dist = vincenty(coords, centers[i]).km\n",
    "        if (dist < min_value):\n",
    "            min_value = dist\n",
    "            mn = i\n",
    "    if (min_value > 10**3):\n",
    "        return -1\n",
    "    return mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XV = X.values\n",
    "X['city_id'] = [city_id([x[5], x[6]]) for x in XV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('train_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = pd.read_csv('train_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testV = test.values\n",
    "test['city_id'] = [city_id([x[3], x[4]]) for x in testV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('test_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv('test_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(X.loc[X['driver_found']==True])\n",
    "print len(y[y==False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_col = ['dist', 'due', 'lat', 'lon', 'f_class', 's_class', 't_class', 'city_id']\n",
    "X_and_test = pd.concat([X[x_col], test[x_col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Используем данные о праздниках отсюда - http://eduscan.net/help/calendar2014 http://newslab.ru/article/559455\n",
    "\n",
    "holidays = \"1.01,2.01,3.01,4.01,5.01,6.01,7.01,8.01,\"\\\n",
    "\"23.02,8.03,9.03,10.03,1.05,2.05,3.05,4.05,9.05,10.05,11.05,12.06,13.06\".split(',')\n",
    "\n",
    "holidays = map(lambda s: tuple(map(int,s.split('.'))),holidays)\n",
    "\n",
    "#вытаскиватель категориальных фичей\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=False,dtype=np.bool)\n",
    "\n",
    "# используем встроенный питоновый парсер времени\n",
    "from dateutil import parser\n",
    "\n",
    "def preprocess_data(X_raw):\n",
    "\n",
    "    #распарсим время\n",
    "    datetimes = list(X_raw.due.apply(lambda x: parser.parse(x)))\n",
    "\n",
    "    #время дня от 0 до 1\n",
    "    rel_times = map(lambda dt: (dt.hour*60 + dt.minute)/(24.*60), datetimes)\n",
    "\n",
    "    #день недели\n",
    "    week_days = map( lambda x: x.isoweekday() , datetimes)\n",
    "\n",
    "    rel_times = np.array(rel_times)\n",
    "    week_days = np.array(week_days)\n",
    "    \n",
    "    is_holiday = map(lambda dt: (dt.day,dt.month) in holidays,\n",
    "                 datetimes)\n",
    "\n",
    "    dow_names = ['mon','tue','wed','thu','fri','sat','sun']\n",
    "    \n",
    "    \n",
    "    data_dict = ( {'city_id':str(city_id), \n",
    "                   'f_class':f,\n",
    "                   's_class':(s if (pd.isnull(s)) else (str(f) + str(s))),\n",
    "                   't_class':(t if (pd.isnull(t)) else(str(f) + str(s) + str(t))),\n",
    "                   'day_of_week':dow_names[day_of_week-1]}\n",
    "                 \n",
    "            for (city_id,f,s,t),day_of_week in zip(X_raw[['city_id', \n",
    "                                                         'f_class',\n",
    "                                                         's_class',\n",
    "                                                         't_class']].values, week_days) )\n",
    "\n",
    "    \n",
    "    Xcat = vectorizer.fit_transform(data_dict)\n",
    "\n",
    "    other_features = [\"dist\",\"lat\",\"lon\"]\n",
    "    \n",
    "    Xreal = X_raw[other_features].values\n",
    "    \n",
    "    \n",
    "    Xfull = np.concatenate([\n",
    "            Xreal,\n",
    "            Xcat            \n",
    "        ],axis=1)\n",
    "    \n",
    "    Xfull = pd.DataFrame(Xfull,columns=other_features+vectorizer.feature_names_)\n",
    "    \n",
    "    Xfull[\"time_of_day_rel\"] = rel_times\n",
    "    Xfull[\"is_holiday\"] = is_holiday\n",
    "\n",
    "    \n",
    "    return Xfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_and_test = preprocess_data(X_and_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_and_test.to_csv('trainplustest_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ если всё упало ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_and_test = pd.read_csv('trainplustest_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y = data['burned'].values\n",
    "X = X_and_test.head(len(y))\n",
    "test = X_and_test[len(y):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape, y.shape, test.shape\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# предскажем cancel_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### лол, cancel_time, не считая -1, имеет логнормальное распределение, значит его имеет смысл предсказывать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cancel_times = data['cancel_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape, cancel_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancel_times = np.log(cancel_times + np.array([2.]*len(cancel_times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trash = plt.hist(cancel_times[cancel_times != 0], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} \n",
    "params['objective']           = \"reg:linear\"\n",
    "# params['booster']             = \"gbtree\"\n",
    "# params['eval_metric']         = \"auc\"\n",
    "params['eta']                 = 0.1\n",
    "# params['max_depth']           = 7\n",
    "# params['subsample']           = 0.681\n",
    "# params['colsample_bytree']    = 0.95\n",
    "params['seed']                = 1337\n",
    "params['njobs']               = -1\n",
    "# params['silent']              = 1\n",
    "bound = int(X.shape[0]*0.9)\n",
    "x_train, x_val = X[:bound], X[bound:]\n",
    "y_train, y_val = cancel_times[:bound], cancel_times[bound:]\n",
    " \n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "# dtest = xgb.DMatrix(test)\n",
    "watchlist = [(dval,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_trees = 300\n",
    "esr = 10\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, verbose_eval=True, early_stopping_rounds = esr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, cancel_times)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_cancel_time = gbm.predict(dtest, ntree_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_cancel_time).to_csv('predicted_cancel_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain_ = xgb.DMatrix(X)\n",
    "train_pred_cancel_time = gbm.predict(dtrain_, ntree_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_pred_cancel_time).to_csv('train_predicted_cancel_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "pred_cancel_times = pd.read_csv('predicted_cancel_times.csv')\n",
    "train_pred_cancel_times = pd.read_csv('train_predicted_cancel_times.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ! Теперь у нас есть pred_cancel_time для test!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# предскажем driver_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver_founds = data['driver_found']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} \n",
    "params['objective']           = \"binary:logistic\"\n",
    "# params['booster']             = \"gbtree\"\n",
    "# params['eval_metric']         = \"auc\"\n",
    "params['eta']                 = 0.05\n",
    "# params['max_depth']           = 7\n",
    "# params['subsample']           = 0.681\n",
    "# params['colsample_bytree']    = 0.95\n",
    "params['seed']                = 1337\n",
    "params['njobs']               = -1\n",
    "# params['silent']              = 1\n",
    "bound = int(X.shape[0]*0.5)\n",
    "x_train, x_val = X[:bound], X[bound:]\n",
    "y_train, y_val = driver_founds[:bound], driver_founds[bound:]\n",
    " \n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "# dtest = xgb.DMatrix(test)\n",
    "watchlist = [(dval,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = 300\n",
    "esr = 10\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, verbose_eval=True, early_stopping_rounds = esr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, driver_founds)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_driver_founds = gbm.predict(dtest, ntree_limit=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_driver_founds).to_csv('predicted_driver_founds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain_ = xgb.DMatrix(X)\n",
    "train_pred_driver_founds = gbm.predict(dtrain_, ntree_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_pred_driver_founds).to_csv('train_predicted_driver_founds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "pred_driver_founds = pd.read_csv('predicted_driver_founds.csv')\n",
    "train_pred_driver_founds = pd.read_csv('train_predicted_driver_founds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# append cancels and drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred_cancel_times.index = X.index\n",
    "del train_pred_cancel_times['Unnamed: 0']\n",
    "X['cancel_times'] = train_pred_cancel_times\n",
    "train_pred_driver_founds.index = X.index\n",
    "del train_pred_driver_founds['Unnamed: 0']\n",
    "X['driver_found'] = train_pred_driver_founds\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_cancel_times.index = test.index\n",
    "del pred_cancel_times['Unnamed: 0']\n",
    "test['cancel_times'] = pred_cancel_times\n",
    "pred_driver_founds.index = test.index\n",
    "del pred_driver_founds['Unnamed: 0']\n",
    "test['driver_found'] = pred_driver_founds\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('X_with_metas.csv')\n",
    "test.to_csv('test_with_metas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# если всё пошло по пизде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_with_metas.csv')\n",
    "test = pd.read_csv('test_with_metas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# добавим vectorized кластеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### в train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Xapp1 = X[:10].copy()\n",
    "# Xapp2 = X[10:20].copy()\n",
    "# Xapp2.index = Xapp1.index\n",
    "\n",
    "# Xres = pd.concat([Xapp1, Xapp2[['lat','lon']]], axis=1,join_axes=[Xapp1.index])\n",
    "# Xres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainclusters = pd.read_csv('train_clusters_vectorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del trainclusters['Unnamed: 0']\n",
    "trainclusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat([X, trainclusters], axis=1, join_axes=[X.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### в test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testclusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testclusters = pd.read_csv('test_clusters_vectorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del testclusters['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.concat([test, testclusters], axis=1, join_axes=[test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X['Unnamed: 0']\n",
    "del X['Unnamed: 0.1']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del test['Unnamed: 0']\n",
    "del test['Unnamed: 0.1']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('X_clust_meta.csv')\n",
    "test.to_csv('test_clust_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_clust_meta.csv')\n",
    "test = pd.read_csv('test_clust_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>city_id=-1</th>\n",
       "      <th>city_id=0</th>\n",
       "      <th>city_id=1</th>\n",
       "      <th>city_id=2</th>\n",
       "      <th>city_id=3</th>\n",
       "      <th>city_id=4</th>\n",
       "      <th>day_of_week=fri</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_id=90</th>\n",
       "      <th>cluster_id=91</th>\n",
       "      <th>cluster_id=92</th>\n",
       "      <th>cluster_id=93</th>\n",
       "      <th>cluster_id=94</th>\n",
       "      <th>cluster_id=95</th>\n",
       "      <th>cluster_id=96</th>\n",
       "      <th>cluster_id=97</th>\n",
       "      <th>cluster_id=98</th>\n",
       "      <th>cluster_id=99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17990.125431</td>\n",
       "      <td>55.750130</td>\n",
       "      <td>37.823242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17990.125431</td>\n",
       "      <td>55.750130</td>\n",
       "      <td>37.823242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11439.391945</td>\n",
       "      <td>55.651582</td>\n",
       "      <td>37.340891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14608.577392</td>\n",
       "      <td>55.633404</td>\n",
       "      <td>37.797595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6070.886393</td>\n",
       "      <td>55.770330</td>\n",
       "      <td>37.519917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dist        lat        lon  city_id=-1  city_id=0  city_id=1  \\\n",
       "0  17990.125431  55.750130  37.823242         0.0        1.0        0.0   \n",
       "1  17990.125431  55.750130  37.823242         0.0        1.0        0.0   \n",
       "2  11439.391945  55.651582  37.340891         0.0        1.0        0.0   \n",
       "3  14608.577392  55.633404  37.797595         0.0        1.0        0.0   \n",
       "4   6070.886393  55.770330  37.519917         0.0        1.0        0.0   \n",
       "\n",
       "   city_id=2  city_id=3  city_id=4  day_of_week=fri      ...        \\\n",
       "0        0.0        0.0        0.0              0.0      ...         \n",
       "1        0.0        0.0        0.0              0.0      ...         \n",
       "2        0.0        0.0        0.0              0.0      ...         \n",
       "3        0.0        0.0        0.0              0.0      ...         \n",
       "4        0.0        0.0        0.0              0.0      ...         \n",
       "\n",
       "   cluster_id=90  cluster_id=91  cluster_id=92  cluster_id=93  cluster_id=94  \\\n",
       "0          False          False          False          False          False   \n",
       "1          False          False          False          False          False   \n",
       "2          False          False          False          False          False   \n",
       "3          False          False          False          False          False   \n",
       "4          False          False          False          False          False   \n",
       "\n",
       "   cluster_id=95  cluster_id=96  cluster_id=97  cluster_id=98  cluster_id=99  \n",
       "0          False          False          False          False          False  \n",
       "1          False          False          False          False          False  \n",
       "2          False          False          False          False          False  \n",
       "3          False          False          False          False          False  \n",
       "4          False          False          False          False          False  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X['Unnamed: 0']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>city_id=-1</th>\n",
       "      <th>city_id=0</th>\n",
       "      <th>city_id=1</th>\n",
       "      <th>city_id=2</th>\n",
       "      <th>city_id=3</th>\n",
       "      <th>city_id=4</th>\n",
       "      <th>day_of_week=fri</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_id=90</th>\n",
       "      <th>cluster_id=91</th>\n",
       "      <th>cluster_id=92</th>\n",
       "      <th>cluster_id=93</th>\n",
       "      <th>cluster_id=94</th>\n",
       "      <th>cluster_id=95</th>\n",
       "      <th>cluster_id=96</th>\n",
       "      <th>cluster_id=97</th>\n",
       "      <th>cluster_id=98</th>\n",
       "      <th>cluster_id=99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1748.201178</td>\n",
       "      <td>55.731713</td>\n",
       "      <td>37.487353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7341.870806</td>\n",
       "      <td>55.973637</td>\n",
       "      <td>37.412352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7398.857088</td>\n",
       "      <td>55.743193</td>\n",
       "      <td>37.427839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11787.335702</td>\n",
       "      <td>55.777737</td>\n",
       "      <td>37.617626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4418.580801</td>\n",
       "      <td>55.785083</td>\n",
       "      <td>37.589114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dist        lat        lon  city_id=-1  city_id=0  city_id=1  \\\n",
       "0   1748.201178  55.731713  37.487353         0.0        1.0        0.0   \n",
       "1   7341.870806  55.973637  37.412352         0.0        1.0        0.0   \n",
       "2   7398.857088  55.743193  37.427839         0.0        1.0        0.0   \n",
       "3  11787.335702  55.777737  37.617626         0.0        1.0        0.0   \n",
       "4   4418.580801  55.785083  37.589114         0.0        1.0        0.0   \n",
       "\n",
       "   city_id=2  city_id=3  city_id=4  day_of_week=fri      ...        \\\n",
       "0        0.0        0.0        0.0              0.0      ...         \n",
       "1        0.0        0.0        0.0              1.0      ...         \n",
       "2        0.0        0.0        0.0              1.0      ...         \n",
       "3        0.0        0.0        0.0              1.0      ...         \n",
       "4        0.0        0.0        0.0              0.0      ...         \n",
       "\n",
       "   cluster_id=90  cluster_id=91  cluster_id=92  cluster_id=93  cluster_id=94  \\\n",
       "0          False          False           True          False          False   \n",
       "1          False          False          False          False          False   \n",
       "2          False          False          False          False          False   \n",
       "3          False          False          False          False          False   \n",
       "4          False          False          False          False          False   \n",
       "\n",
       "   cluster_id=95  cluster_id=96  cluster_id=97  cluster_id=98  cluster_id=99  \n",
       "0          False          False          False          False          False  \n",
       "1          False          False          False          False          False  \n",
       "2          False          False          False          False          False  \n",
       "3          False          False          False          False          False  \n",
       "4          False          False          False          False          False  \n",
       "\n",
       "[5 rows x 266 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test['Unnamed: 0']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del y['Unnamed: 0']\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.index = np.arange(0, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = pd.Series(y['burned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} \n",
    "params['objective']           = \"binary:logistic\" \n",
    "params['booster']             = \"gbtree\"\n",
    "params['eval_metric']         = \"auc\"\n",
    "params['eta']                 = 0.006\n",
    "params['max_depth']           = 7\n",
    "params['subsample']           = 0.681\n",
    "params['colsample_bytree']    = 0.95\n",
    "params['seed']                = 18\n",
    "params['njobs']               = -1\n",
    "params['silent']              = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1793300, 266), (1793300,), (743463, 266))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bound = int(X.shape[0]*0.9)\n",
    "x_train, x_val = X[:bound], X[bound:]\n",
    "y_train, y_val = y[:bound], y[bound:]\n",
    " \n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "dtest = xgb.DMatrix(test)\n",
    "watchlist = [(dval,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = 5000\n",
    "esr = 12\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, verbose_eval=True, early_stopping_rounds = esr)\n",
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, y)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, 2000)\n",
    "gbm.save_model('clust_meta.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = gbm.predict(dtest, ntree_limit=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(test.shape[0])\n",
    "response[\"Y_prob\"] = prediction\n",
    " \n",
    "response.to_csv('stacksub.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction = gbm.predict(dtrain, ntree_limit=780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# response = pd.DataFrame()\n",
    "# response[\"Ids\"] = np.arange(X.shape[0])\n",
    "# response[\"Y_prob\"] = prediction\n",
    " \n",
    "# response.to_csv('train779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Также обучим более \"случайную\" версию RandomForest\n",
    "model = RandomForestClassifier(n_estimators=779,n_jobs=16,min_samples_split=75,min_samples_leaf=20)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res = res[:, 1]\n",
    "\n",
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(test.shape[0])\n",
    "response[\"Y_prob\"] = res\n",
    " \n",
    "response.to_csv('rf_test779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = model.predict_proba(X)\n",
    "\n",
    "# res = res[:, 1]\n",
    "\n",
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(X.shape[0])\n",
    "response[\"Y_prob\"] = res\n",
    " \n",
    "response.to_csv('rf_train779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.corr(res, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from datanight import plot_forest_feature_importances\n",
    "# plot_forest_feature_importances(model,X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from datanight import generate_submission\n",
    "# generate_submission(preprocess_data,model,\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Советы по улучшению модели:\n",
    "\n",
    "* Смотри глазами на данные - строй графики, исследуй аномалия \n",
    " * это может принести новые идеи и отбросить нежизнеспособные намного раньше \n",
    " * Туториал по библиотеке, в которой можно строить графики \n",
    "   * http://matplotlib.org/users/pyplot_tutorial.html\n",
    " * Ключевой вопрос самому себе - __\"От чего ещё может зависеть, сгорит ли заказ?\"__\n",
    "\n",
    "\n",
    "* Попробуй более точно настроить модель или выбрать другую\n",
    " * Random Forest с текущими параметрами можно улучшить\n",
    "   * Документация по нему - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    " * А можно использовать другие, более подходящие методы\n",
    "   * Документация по методам - http://scikit-learn.org/stable/supervised_learning.html\n",
    " * Наконец, модели можно комбинировать\n",
    "   * Например, усреднять с весами\n",
    "   * В итоге качество может быть лучше, чем у каждой модели по отдельности\n",
    " * Важно не увлечься - зачастую качественные изменения решения намного лучше подкручивания параметров\n",
    "\n",
    "\n",
    "* Подумай, какие ещё дополнительные данные можно провязать с выборкой? \n",
    " * насколько реально применить их за отведённое время?\n",
    "\n",
    "\n",
    "* __Главное__ - пытайся понять, дадут ли твои улучшения прирост на новых данных\n",
    " * Тестовая выборка находится по времени дальше, чем обучающая.\n",
    "   * Например, нельзя использовать номер дня в году, потому что мы обучаемся на выборке __ДО__ начала контрольной\n",
    " * Это не значит, что нужно отправлять миллион решений на проверку и выбирать лучшее - это приведёт к переобучению\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
