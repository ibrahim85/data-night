{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим данные\n",
    " * При первом запуске скачаем train.csv и evaluation.csv\n",
    " * При повторных запусках файлы уже будут на месте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = data.loc[data['cancel_time']<5000]\n",
    "X = data[data.columns[:len(data.columns)-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = data['burned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(X[X['cancel_time']<0])*1./len(X)\n",
    "# X = X.loc[X['cancel_time']<500]\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# X_notminusone = X.loc[X['cancel_time']!=-1]\n",
    "# trsh = plt.hist(np.log(np.array([1.]*len(X_notminusone)) + X_notminusone['cancel_time'].values), bins=2000)\n",
    "# plt.xlim(0., 7.)\n",
    "# plt.ylim(0., 3000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 8))\n",
    "# trash = plt.hist( data.loc[(data['burned']==1) & (data['cancel_time']<100000)]['cancel_time'], bins=1000 )\n",
    "# plt.ylim(0, 5000)\n",
    "# plt.xlim(0, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.loc[(data['burned']==0)]['cancel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.loc[(data['burned']==1)]['cancel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# citycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!!!!!\n",
    "# X = pd.DataFrame.from_csv(\"./train_with_cityid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = [\n",
    "    [55.754216, 37.61343],  #0\n",
    "    [51.661535, 39.200287], #1\n",
    "    [56.326887, 44.005986], #2\n",
    "    [55.798551, 49.106324], #3\n",
    "    [59.939095, 30.315868]  #4\n",
    "]\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "minminmin = 10**15\n",
    "\n",
    "def city_id(coords):\n",
    "    mn = 0\n",
    "    min_value = minminmin\n",
    "    for i in range(len(centers)):\n",
    "        \n",
    "        dist = vincenty(coords, centers[i]).km\n",
    "        if (dist < min_value):\n",
    "            min_value = dist\n",
    "            mn = i\n",
    "    if (min_value > 10**3):\n",
    "        return -1\n",
    "    return mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XV = X.values\n",
    "X['city_id'] = [city_id([x[5], x[6]]) for x in XV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('train_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = pd.read_csv('train_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testV = test.values\n",
    "test['city_id'] = [city_id([x[3], x[4]]) for x in testV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('test_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv('test_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(X.loc[X['driver_found']==True])\n",
    "print len(y[y==False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_col = ['dist', 'due', 'lat', 'lon', 'f_class', 's_class', 't_class', 'city_id']\n",
    "X_and_test = pd.concat([X[x_col], test[x_col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Используем данные о праздниках отсюда - http://eduscan.net/help/calendar2014 http://newslab.ru/article/559455\n",
    "\n",
    "holidays = \"1.01,2.01,3.01,4.01,5.01,6.01,7.01,8.01,\"\\\n",
    "\"23.02,8.03,9.03,10.03,1.05,2.05,3.05,4.05,9.05,10.05,11.05,12.06,13.06\".split(',')\n",
    "\n",
    "holidays = map(lambda s: tuple(map(int,s.split('.'))),holidays)\n",
    "\n",
    "#вытаскиватель категориальных фичей\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=False,dtype=np.bool)\n",
    "\n",
    "# используем встроенный питоновый парсер времени\n",
    "from dateutil import parser\n",
    "\n",
    "def preprocess_data(X_raw):\n",
    "\n",
    "    #распарсим время\n",
    "    datetimes = list(X_raw.due.apply(lambda x: parser.parse(x)))\n",
    "\n",
    "    #время дня от 0 до 1\n",
    "    rel_times = map(lambda dt: (dt.hour*60 + dt.minute)/(24.*60), datetimes)\n",
    "\n",
    "    #день недели\n",
    "    week_days = map( lambda x: x.isoweekday() , datetimes)\n",
    "\n",
    "    rel_times = np.array(rel_times)\n",
    "    week_days = np.array(week_days)\n",
    "    \n",
    "    is_holiday = map(lambda dt: (dt.day,dt.month) in holidays,\n",
    "                 datetimes)\n",
    "\n",
    "    dow_names = ['mon','tue','wed','thu','fri','sat','sun']\n",
    "    \n",
    "    \n",
    "    data_dict = ( {'city_id':str(city_id), \n",
    "                   'f_class':f,\n",
    "                   's_class':(s if (pd.isnull(s)) else (str(f) + str(s))),\n",
    "                   't_class':(t if (pd.isnull(t)) else(str(f) + str(s) + str(t))),\n",
    "                   'day_of_week':dow_names[day_of_week-1]}\n",
    "                 \n",
    "            for (city_id,f,s,t),day_of_week in zip(X_raw[['city_id', \n",
    "                                                         'f_class',\n",
    "                                                         's_class',\n",
    "                                                         't_class']].values, week_days) )\n",
    "\n",
    "    \n",
    "    Xcat = vectorizer.fit_transform(data_dict)\n",
    "\n",
    "    other_features = [\"dist\",\"lat\",\"lon\"]\n",
    "    \n",
    "    Xreal = X_raw[other_features].values\n",
    "    \n",
    "    \n",
    "    Xfull = np.concatenate([\n",
    "            Xreal,\n",
    "            Xcat            \n",
    "        ],axis=1)\n",
    "    \n",
    "    Xfull = pd.DataFrame(Xfull,columns=other_features+vectorizer.feature_names_)\n",
    "    \n",
    "    Xfull[\"time_of_day_rel\"] = rel_times\n",
    "    Xfull[\"is_holiday\"] = is_holiday\n",
    "\n",
    "    \n",
    "    return Xfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_and_test = preprocess_data(X_and_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_and_test.to_csv('trainplustest_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ если всё упало ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_and_test = pd.read_csv('trainplustest_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y = data['burned'].values\n",
    "X = X_and_test.head(len(y))\n",
    "test = X_and_test[len(y):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1793300, 37) (1793300,) (743463, 37)\n",
      "(1793300, 10)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, y.shape, test.shape\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# предскажем cancel_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cancel_times = data['cancel_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape, cancel_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancel_times = np.log(cancel_times + np.array([2.]*len(cancel_times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trash = plt.hist(cancel_times[cancel_times != 0], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} \n",
    "params['objective']           = \"reg:linear\"\n",
    "# params['booster']             = \"gbtree\"\n",
    "# params['eval_metric']         = \"auc\"\n",
    "params['eta']                 = 0.1\n",
    "# params['max_depth']           = 7\n",
    "# params['subsample']           = 0.681\n",
    "# params['colsample_bytree']    = 0.95\n",
    "params['seed']                = 1337\n",
    "params['njobs']               = -1\n",
    "# params['silent']              = 1\n",
    "bound = int(X.shape[0]*0.9)\n",
    "x_train, x_val = X[:bound], X[bound:]\n",
    "y_train, y_val = cancel_times[:bound], cancel_times[bound:]\n",
    " \n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "# dtest = xgb.DMatrix(test)\n",
    "watchlist = [(dval,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_trees = 300\n",
    "esr = 10\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, verbose_eval=True, early_stopping_rounds = esr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, cancel_times)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_cancel_time = gbm.predict(dtest, ntree_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_cancel_time).to_csv('predicted_cancel_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain_ = xgb.DMatrix(X)\n",
    "train_pred_cancel_time = gbm.predict(dtrain_, ntree_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_pred_cancel_time).to_csv('train_predicted_cancel_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "pred_cancel_times = pd.read_csv('predicted_cancel_times.csv')\n",
    "train_pred_cancel_times = pd.read_csv('train_predicted_cancel_times.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ! Теперь у нас есть pred_cancel_time для test!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# предскажем driver_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver_founds = data['driver_found']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} \n",
    "params['objective']           = \"binary:logistic\"\n",
    "# params['booster']             = \"gbtree\"\n",
    "# params['eval_metric']         = \"auc\"\n",
    "params['eta']                 = 0.05\n",
    "# params['max_depth']           = 7\n",
    "# params['subsample']           = 0.681\n",
    "# params['colsample_bytree']    = 0.95\n",
    "params['seed']                = 1337\n",
    "params['njobs']               = -1\n",
    "# params['silent']              = 1\n",
    "bound = int(X.shape[0]*0.5)\n",
    "x_train, x_val = X[:bound], X[bound:]\n",
    "y_train, y_val = driver_founds[:bound], driver_founds[bound:]\n",
    " \n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "# dtest = xgb.DMatrix(test)\n",
    "watchlist = [(dval,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = 300\n",
    "esr = 10\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, verbose_eval=True, early_stopping_rounds = esr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, driver_founds)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_driver_founds = gbm.predict(dtest, ntree_limit=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_driver_founds).to_csv('predicted_driver_founds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain_ = xgb.DMatrix(X)\n",
    "train_pred_driver_founds = gbm.predict(dtrain_, ntree_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_pred_driver_founds).to_csv('train_predicted_driver_founds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "pred_driver_founds = pd.read_csv('predicted_driver_founds.csv')\n",
    "train_pred_driver_founds = pd.read_csv('train_predicted_driver_founds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# append cancels and drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dist</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>city_id=-1</th>\n",
       "      <th>city_id=0</th>\n",
       "      <th>city_id=1</th>\n",
       "      <th>city_id=2</th>\n",
       "      <th>city_id=3</th>\n",
       "      <th>city_id=4</th>\n",
       "      <th>...</th>\n",
       "      <th>t_class=businesseconomvip</th>\n",
       "      <th>t_class=businessvipeconom</th>\n",
       "      <th>t_class=econombusinessvip</th>\n",
       "      <th>t_class=economvipbusiness</th>\n",
       "      <th>t_class=vipbusinesseconom</th>\n",
       "      <th>t_class=vipeconombusiness</th>\n",
       "      <th>time_of_day_rel</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>cancel_times</th>\n",
       "      <th>driver_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17990.125431</td>\n",
       "      <td>55.75013</td>\n",
       "      <td>37.823242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>True</td>\n",
       "      <td>1.311234</td>\n",
       "      <td>0.827348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          dist       lat        lon  city_id=-1  city_id=0  \\\n",
       "0           0  17990.125431  55.75013  37.823242         0.0        1.0   \n",
       "\n",
       "   city_id=1  city_id=2  city_id=3  city_id=4      ...       \\\n",
       "0        0.0        0.0        0.0        0.0      ...        \n",
       "\n",
       "   t_class=businesseconomvip  t_class=businessvipeconom  \\\n",
       "0                        0.0                        0.0   \n",
       "\n",
       "   t_class=econombusinessvip  t_class=economvipbusiness  \\\n",
       "0                        0.0                        0.0   \n",
       "\n",
       "   t_class=vipbusinesseconom  t_class=vipeconombusiness  time_of_day_rel  \\\n",
       "0                        0.0                        0.0          0.00625   \n",
       "\n",
       "   is_holiday  cancel_times  driver_found  \n",
       "0        True      1.311234      0.827348  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_cancel_times.index = X.index\n",
    "del train_pred_cancel_times['Unnamed: 0']\n",
    "X['cancel_times'] = train_pred_cancel_times\n",
    "train_pred_driver_founds.index = X.index\n",
    "del train_pred_driver_founds['Unnamed: 0']\n",
    "X['driver_found'] = train_pred_driver_founds\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/ubuntu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dist</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>city_id=-1</th>\n",
       "      <th>city_id=0</th>\n",
       "      <th>city_id=1</th>\n",
       "      <th>city_id=2</th>\n",
       "      <th>city_id=3</th>\n",
       "      <th>city_id=4</th>\n",
       "      <th>...</th>\n",
       "      <th>t_class=businesseconomvip</th>\n",
       "      <th>t_class=businessvipeconom</th>\n",
       "      <th>t_class=econombusinessvip</th>\n",
       "      <th>t_class=economvipbusiness</th>\n",
       "      <th>t_class=vipbusinesseconom</th>\n",
       "      <th>t_class=vipeconombusiness</th>\n",
       "      <th>time_of_day_rel</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>cancel_times</th>\n",
       "      <th>driver_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1793300</th>\n",
       "      <td>1793300</td>\n",
       "      <td>1748.201178</td>\n",
       "      <td>55.731713</td>\n",
       "      <td>37.487353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>False</td>\n",
       "      <td>0.766411</td>\n",
       "      <td>0.844935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         dist        lat        lon  city_id=-1  city_id=0  \\\n",
       "1793300     1793300  1748.201178  55.731713  37.487353         0.0        1.0   \n",
       "\n",
       "         city_id=1  city_id=2  city_id=3  city_id=4      ...       \\\n",
       "1793300        0.0        0.0        0.0        0.0      ...        \n",
       "\n",
       "         t_class=businesseconomvip  t_class=businessvipeconom  \\\n",
       "1793300                        0.0                        0.0   \n",
       "\n",
       "         t_class=econombusinessvip  t_class=economvipbusiness  \\\n",
       "1793300                        1.0                        0.0   \n",
       "\n",
       "         t_class=vipbusinesseconom  t_class=vipeconombusiness  \\\n",
       "1793300                        0.0                        0.0   \n",
       "\n",
       "         time_of_day_rel  is_holiday  cancel_times  driver_found  \n",
       "1793300         0.760417       False      0.766411      0.844935  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cancel_times.index = test.index\n",
    "del pred_cancel_times['Unnamed: 0']\n",
    "test['cancel_times'] = pred_cancel_times\n",
    "pred_driver_founds.index = test.index\n",
    "del pred_driver_founds['Unnamed: 0']\n",
    "test['driver_found'] = pred_driver_founds\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} \n",
    "params['objective']           = \"binary:logistic\" \n",
    "params['booster']             = \"gbtree\"\n",
    "params['eval_metric']         = \"auc\"\n",
    "params['eta']                 = 0.006\n",
    "params['max_depth']           = 7\n",
    "params['subsample']           = 0.681\n",
    "params['colsample_bytree']    = 0.95\n",
    "params['seed']                = 1337\n",
    "params['njobs']               = -1\n",
    "params['silent']              = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bound = int(X.shape[0]*0.9)\n",
    "x_train, x_val = X[:bound], X[bound:]\n",
    "y_train, y_val = y[:bound], y[bound:]\n",
    " \n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "dtest = xgb.DMatrix(test)\n",
    "watchlist = [(dval,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 12 rounds.\n",
      "[0]\teval-auc:0.666840\n",
      "[1]\teval-auc:0.665799\n",
      "[2]\teval-auc:0.667321\n"
     ]
    }
   ],
   "source": [
    "num_trees = 5000\n",
    "esr = 12\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, verbose_eval=True, early_stopping_rounds = esr)\n",
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, y)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, 780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = gbm.predict(dtest, ntree_limit=780)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(test.shape[0])\n",
    "response[\"Y_prob\"] = prediction\n",
    " \n",
    "response.to_csv('kek779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = gbm.predict(dtrain, ntree_limit=780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(X.shape[0])\n",
    "response[\"Y_prob\"] = prediction\n",
    " \n",
    "response.to_csv('train779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Также обучим более \"случайную\" версию RandomForest\n",
    "model = RandomForestClassifier(n_estimators=779,n_jobs=16,min_samples_split=75,min_samples_leaf=20)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res = res[:, 1]\n",
    "\n",
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(test.shape[0])\n",
    "response[\"Y_prob\"] = res\n",
    " \n",
    "response.to_csv('rf_test779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = model.predict_proba(X)\n",
    "\n",
    "# res = res[:, 1]\n",
    "\n",
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(X.shape[0])\n",
    "response[\"Y_prob\"] = res\n",
    " \n",
    "response.to_csv('rf_train779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.corr(res, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from datanight import plot_forest_feature_importances\n",
    "# plot_forest_feature_importances(model,X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from datanight import generate_submission\n",
    "# generate_submission(preprocess_data,model,\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Советы по улучшению модели:\n",
    "\n",
    "* Смотри глазами на данные - строй графики, исследуй аномалия \n",
    " * это может принести новые идеи и отбросить нежизнеспособные намного раньше \n",
    " * Туториал по библиотеке, в которой можно строить графики \n",
    "   * http://matplotlib.org/users/pyplot_tutorial.html\n",
    " * Ключевой вопрос самому себе - __\"От чего ещё может зависеть, сгорит ли заказ?\"__\n",
    "\n",
    "\n",
    "* Попробуй более точно настроить модель или выбрать другую\n",
    " * Random Forest с текущими параметрами можно улучшить\n",
    "   * Документация по нему - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    " * А можно использовать другие, более подходящие методы\n",
    "   * Документация по методам - http://scikit-learn.org/stable/supervised_learning.html\n",
    " * Наконец, модели можно комбинировать\n",
    "   * Например, усреднять с весами\n",
    "   * В итоге качество может быть лучше, чем у каждой модели по отдельности\n",
    " * Важно не увлечься - зачастую качественные изменения решения намного лучше подкручивания параметров\n",
    "\n",
    "\n",
    "* Подумай, какие ещё дополнительные данные можно провязать с выборкой? \n",
    " * насколько реально применить их за отведённое время?\n",
    "\n",
    "\n",
    "* __Главное__ - пытайся понять, дадут ли твои улучшения прирост на новых данных\n",
    " * Тестовая выборка находится по времени дальше, чем обучающая.\n",
    "   * Например, нельзя использовать номер дня в году, потому что мы обучаемся на выборке __ДО__ начала контрольной\n",
    " * Это не значит, что нужно отправлять миллион решений на проверку и выбирать лучшее - это приведёт к переобучению\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
