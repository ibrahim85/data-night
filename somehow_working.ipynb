{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = pd.DataFrame.from_csv(\"../train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame.from_csv('X_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_csv('test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame.from_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(X[X['cancel_time']<0])*1./len(X)\n",
    "# X = X.loc[X['cancel_time']<500]\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# X_notminusone = X.loc[X['cancel_time']!=-1]\n",
    "# trsh = plt.hist(np.log(np.array([1.]*len(X_notminusone)) + X_notminusone['cancel_time'].values), bins=2000)\n",
    "# plt.xlim(0., 7.)\n",
    "# plt.ylim(0., 3000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 8))\n",
    "# trash = plt.hist( data.loc[(data['burned']==1) & (data['cancel_time']<100000)]['cancel_time'], bins=1000 )\n",
    "# plt.ylim(0, 5000)\n",
    "# plt.xlim(0, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.loc[(data['burned']==0)]['cancel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.loc[(data['burned']==1)]['cancel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# предскажем cancel_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### лол, cancel_time, не считая -1, имеет логнормальное распределение, значит его имеет смысл предсказывать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cancel_times = data['cancel_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape, cancel_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancel_times = np.log(cancel_times + np.array([2.]*len(cancel_times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trash = plt.hist(cancel_times[cancel_times != 0], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} \n",
    "params['objective']           = \"reg:linear\"\n",
    "# params['booster']             = \"gbtree\"\n",
    "# params['eval_metric']         = \"auc\"\n",
    "params['eta']                 = 0.1\n",
    "# params['max_depth']           = 7\n",
    "# params['subsample']           = 0.681\n",
    "# params['colsample_bytree']    = 0.95\n",
    "params['seed']                = 1337\n",
    "params['njobs']               = -1\n",
    "# params['silent']              = 1\n",
    "bound = int(X.shape[0]*0.9)\n",
    "x_train, x_val = X[:bound], X[bound:]\n",
    "y_train, y_val = cancel_times[:bound], cancel_times[bound:]\n",
    " \n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "# dtest = xgb.DMatrix(test)\n",
    "watchlist = [(dval,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_trees = 300\n",
    "esr = 10\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, verbose_eval=True, early_stopping_rounds = esr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, cancel_times)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_cancel_time = gbm.predict(dtest, ntree_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_cancel_time).to_csv('predicted_cancel_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain_ = xgb.DMatrix(X)\n",
    "train_pred_cancel_time = gbm.predict(dtrain_, ntree_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_pred_cancel_time).to_csv('train_predicted_cancel_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "pred_cancel_times = pd.read_csv('predicted_cancel_times.csv')\n",
    "train_pred_cancel_times = pd.read_csv('train_predicted_cancel_times.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ! Теперь у нас есть pred_cancel_time для test!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# предскажем driver_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver_founds = data['driver_found']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} \n",
    "params['objective']           = \"binary:logistic\"\n",
    "# params['booster']             = \"gbtree\"\n",
    "# params['eval_metric']         = \"auc\"\n",
    "params['eta']                 = 0.05\n",
    "# params['max_depth']           = 7\n",
    "# params['subsample']           = 0.681\n",
    "# params['colsample_bytree']    = 0.95\n",
    "params['seed']                = 1337\n",
    "params['njobs']               = -1\n",
    "# params['silent']              = 1\n",
    "bound = int(X.shape[0]*0.9)\n",
    "x_train, x_val = X[:bound], X[bound:]\n",
    "y_train, y_val = driver_founds[:bound], driver_founds[bound:]\n",
    " \n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "# dtest = xgb.DMatrix(test)\n",
    "watchlist = [(dval,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = 300\n",
    "esr = 10\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, verbose_eval=True, early_stopping_rounds = esr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, driver_founds)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_driver_founds = gbm.predict(dtest, ntree_limit=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(pred_driver_founds).to_csv('predicted_driver_founds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain_ = xgb.DMatrix(X)\n",
    "train_pred_driver_founds = gbm.predict(dtrain_, ntree_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train_pred_driver_founds).to_csv('train_predicted_driver_founds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "pred_driver_founds = pd.read_csv('predicted_driver_founds.csv')\n",
    "train_pred_driver_founds = pd.read_csv('train_predicted_driver_founds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# append cancels and drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred_cancel_times.index = X.index\n",
    "del train_pred_cancel_times['Unnamed: 0']\n",
    "X['cancel_times'] = train_pred_cancel_times\n",
    "train_pred_driver_founds.index = X.index\n",
    "del train_pred_driver_founds['Unnamed: 0']\n",
    "X['driver_found'] = train_pred_driver_founds\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_cancel_times.index = test.index\n",
    "del pred_cancel_times['Unnamed: 0']\n",
    "test['cancel_times'] = pred_cancel_times\n",
    "pred_driver_founds.index = test.index\n",
    "del pred_driver_founds['Unnamed: 0']\n",
    "test['driver_found'] = pred_driver_founds\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('X_with_metas.csv')\n",
    "test.to_csv('test_with_metas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# если всё пошло по пизде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_with_metas.csv')\n",
    "test = pd.read_csv('test_with_metas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# добавим vectorized кластеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### в train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Xapp1 = X[:10].copy()\n",
    "# Xapp2 = X[10:20].copy()\n",
    "# Xapp2.index = Xapp1.index\n",
    "\n",
    "# Xres = pd.concat([Xapp1, Xapp2[['lat','lon']]], axis=1,join_axes=[Xapp1.index])\n",
    "# Xres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainclusters = pd.read_csv('train_clusters_vectorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del trainclusters['Unnamed: 0']\n",
    "trainclusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat([X, trainclusters], axis=1, join_axes=[X.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### в test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testclusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testclusters = pd.read_csv('test_clusters_vectorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del testclusters['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.concat([test, testclusters], axis=1, join_axes=[test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X['Unnamed: 0']\n",
    "del X['Unnamed: 0.1']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del test['Unnamed: 0']\n",
    "del test['Unnamed: 0.1']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('X_clust_meta.csv')\n",
    "test.to_csv('test_clust_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_clust_meta.csv')\n",
    "test = pd.read_csv('test_clust_meta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst = xgb.Booster({'nthread':16}) #init model\n",
    "bst.load_model(\"clust_meta.model\") # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest_X = xgb.DMatrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_X = bst.predict(dtest_X, ntree_limit=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X['xgb2000'] = prediction_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_test = bst.predict(dtest, ntree_limit=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['xgb2000'] = prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Также обучим более \"случайную\" версию RandomForest\n",
    "model = RandomForestClassifier(n_estimators=1000,n_jobs=16,min_samples_split=75,min_samples_leaf=20)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "rf1k_test = model.predict_proba(test)\n",
    "rf1k_X = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn.tree.DecisionTreeClassifier, RandomForestClassifier, AdaBoostClassifier, LinearModel.Ridge\n",
    "# >>> from sklearn.ensemble import BaggingClassifier\n",
    "# >>> from sklearn.neighbors import KNeighborsClassifier\n",
    "# >>> bagging = BaggingClassifier(KNeighborsClassifier(),\n",
    "# ...                             max_samples=0.5, max_features=0.5)\n",
    "# class sklearn.ensemble.BaggingClassifier(base_estimator=None, n_estimators=10, \n",
    "#                                          max_samples=1.0, max_features=1.0, bootstrap=True, \n",
    "#                                          bootstrap_features=False, oob_score=False, \n",
    "#                                          warm_start=False, n_jobs=1, \n",
    "#                                          random_state=None, verbose=0)[source]\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(), \n",
    "                            n_estimators = 200, \n",
    "                            max_samples=0.5, \n",
    "                            max_features=0.5,\n",
    "                            n_jobs=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X['Unnamed: 0']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del test['Unnamed: 0']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del y['Unnamed: 0']\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.index = np.arange(0, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = pd.Series(y['burned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {} \n",
    "params['objective']           = \"binary:logistic\" \n",
    "params['booster']             = \"gbtree\"\n",
    "params['eval_metric']         = \"auc\"\n",
    "params['eta']                 = 0.006\n",
    "params['max_depth']           = 7\n",
    "params['subsample']           = 0.681\n",
    "params['colsample_bytree']    = 0.95\n",
    "params['seed']                = 18\n",
    "params['njobs']               = -1\n",
    "params['silent']              = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bound = int(X.shape[0]*0.9)\n",
    "x_train, x_val = X[:bound], X[bound:]\n",
    "y_train, y_val = y[:bound], y[bound:]\n",
    " \n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dval = xgb.DMatrix(x_val, y_val)\n",
    "dtest = xgb.DMatrix(test)\n",
    "watchlist = [(dval,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_trees = 5000\n",
    "esr = 12\n",
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, verbose_eval=True, early_stopping_rounds = esr)\n",
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, y)\n",
    "dtest = xgb.DMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm = xgb.train(params, dtrain, 2000)\n",
    "gbm.save_model('clust_meta.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = gbm.predict(dtest, ntree_limit=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(test.shape[0])\n",
    "response[\"Y_prob\"] = prediction\n",
    " \n",
    "response.to_csv('stacksub.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction = gbm.predict(dtrain, ntree_limit=780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# response = pd.DataFrame()\n",
    "# response[\"Ids\"] = np.arange(X.shape[0])\n",
    "# response[\"Y_prob\"] = prediction\n",
    " \n",
    "# response.to_csv('train779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Также обучим более \"случайную\" версию RandomForest\n",
    "model = RandomForestClassifier(n_estimators=1000,n_jobs=16,min_samples_split=75,min_samples_leaf=20)\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf1k_test = model.predict_proba(test)\n",
    "rf1k_X = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf1k_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res = res[:, 1]\n",
    "\n",
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(test.shape[0])\n",
    "response[\"Y_prob\"] = res\n",
    " \n",
    "response.to_csv('rf_test779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = model.predict_proba(X)\n",
    "\n",
    "# res = res[:, 1]\n",
    "\n",
    "response = pd.DataFrame()\n",
    "response[\"Ids\"] = np.arange(X.shape[0])\n",
    "response[\"Y_prob\"] = res\n",
    " \n",
    "response.to_csv('rf_train779.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.corr(res, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from datanight import plot_forest_feature_importances\n",
    "# plot_forest_feature_importances(model,X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from datanight import generate_submission\n",
    "# generate_submission(preprocess_data,model,\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Советы по улучшению модели:\n",
    "\n",
    "* Смотри глазами на данные - строй графики, исследуй аномалия \n",
    " * это может принести новые идеи и отбросить нежизнеспособные намного раньше \n",
    " * Туториал по библиотеке, в которой можно строить графики \n",
    "   * http://matplotlib.org/users/pyplot_tutorial.html\n",
    " * Ключевой вопрос самому себе - __\"От чего ещё может зависеть, сгорит ли заказ?\"__\n",
    "\n",
    "\n",
    "* Попробуй более точно настроить модель или выбрать другую\n",
    " * Random Forest с текущими параметрами можно улучшить\n",
    "   * Документация по нему - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    " * А можно использовать другие, более подходящие методы\n",
    "   * Документация по методам - http://scikit-learn.org/stable/supervised_learning.html\n",
    " * Наконец, модели можно комбинировать\n",
    "   * Например, усреднять с весами\n",
    "   * В итоге качество может быть лучше, чем у каждой модели по отдельности\n",
    " * Важно не увлечься - зачастую качественные изменения решения намного лучше подкручивания параметров\n",
    "\n",
    "\n",
    "* Подумай, какие ещё дополнительные данные можно провязать с выборкой? \n",
    " * насколько реально применить их за отведённое время?\n",
    "\n",
    "\n",
    "* __Главное__ - пытайся понять, дадут ли твои улучшения прирост на новых данных\n",
    " * Тестовая выборка находится по времени дальше, чем обучающая.\n",
    "   * Например, нельзя использовать номер дня в году, потому что мы обучаемся на выборке __ДО__ начала контрольной\n",
    " * Это не значит, что нужно отправлять миллион решений на проверку и выбирать лучшее - это приведёт к переобучению\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
