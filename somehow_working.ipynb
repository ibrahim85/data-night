{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим данные\n",
    " * При первом запуске скачаем train.csv и evaluation.csv\n",
    " * При повторных запусках файлы уже будут на месте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancel_time</th>\n",
       "      <th>dist</th>\n",
       "      <th>driver_found</th>\n",
       "      <th>due</th>\n",
       "      <th>f_class</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>s_class</th>\n",
       "      <th>t_class</th>\n",
       "      <th>burned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>55</td>\n",
       "      <td>17990.125431</td>\n",
       "      <td>False</td>\n",
       "      <td>2014-01-01 00:09:32.000</td>\n",
       "      <td>econom</td>\n",
       "      <td>55.75013</td>\n",
       "      <td>37.823242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cancel_time          dist driver_found                      due f_class  \\\n",
       "60           55  17990.125431        False  2014-01-01 00:09:32.000  econom   \n",
       "\n",
       "         lat        lon s_class t_class burned  \n",
       "60  55.75013  37.823242     NaN     NaN   True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9578409204512395"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data['cancel_time']<500])*1./ len(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.loc[data['cancel_time']<500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# попредсказываем cancel_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 8))\n",
    "# trash = plt.hist( data.loc[(data['burned']==1) & (data['cancel_time']<100000)]['cancel_time'], bins=1000 )\n",
    "# plt.ylim(0, 5000)\n",
    "# plt.xlim(0, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.loc[(data['burned']==0)]['cancel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data.loc[(data['burned']==1)]['cancel_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "      <th>due</th>\n",
       "      <th>f_class</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>s_class</th>\n",
       "      <th>t_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ids</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1748.201178</td>\n",
       "      <td>2014-04-19 18:15:00.000</td>\n",
       "      <td>econom</td>\n",
       "      <td>55.731713</td>\n",
       "      <td>37.487353</td>\n",
       "      <td>business</td>\n",
       "      <td>vip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dist                      due f_class        lat        lon  \\\n",
       "Ids                                                                       \n",
       "0    1748.201178  2014-04-19 18:15:00.000  econom  55.731713  37.487353   \n",
       "\n",
       "      s_class t_class  \n",
       "Ids                    \n",
       "0    business     vip  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[data.columns[:len(data.columns)-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# citycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!!!!!\n",
    "X = pd.DataFrame.from_csv(\"./train_with_cityid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = [\n",
    "    [55.754216, 37.61343],  #0\n",
    "    [51.661535, 39.200287], #1\n",
    "    [56.326887, 44.005986], #2\n",
    "    [55.798551, 49.106324], #3\n",
    "    [59.939095, 30.315868]  #4\n",
    "]\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "minminmin = 10**15\n",
    "\n",
    "def city_id(coords):\n",
    "    mn = 0\n",
    "    min_value = minminmin\n",
    "    for i in range(len(centers)):\n",
    "        \n",
    "        dist = vincenty(coords, centers[i]).km\n",
    "        if (dist < min_value):\n",
    "            min_value = dist\n",
    "            mn = i\n",
    "    if (min_value > 10**3):\n",
    "        return -1\n",
    "    return mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XV = X.values\n",
    "X['city_id'] = [city_id([x[5], x[6]]) for x in XV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('train_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('train_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testV = test.values\n",
    "test['city_id'] = [city_id([x[3], x[4]]) for x in testV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('test_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_with_cityid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_col = ['dist', 'due', 'lat', 'lon', 'f_class', 's_class', 't_class', 'city_id']\n",
    "# X_and_test = pd.concat([X_copy[x_col], test_copy[x_col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Используем данные о праздниках отсюда - http://eduscan.net/help/calendar2014 http://newslab.ru/article/559455\n",
    "\n",
    "holidays = \"1.01,2.01,3.01,4.01,5.01,6.01,7.01,8.01,\"\\\n",
    "\"23.02,8.03,9.03,10.03,1.05,2.05,3.05,4.05,9.05,10.05,11.05,12.06,13.06\".split(',')\n",
    "\n",
    "holidays = map(lambda s: tuple(map(int,s.split('.'))),holidays)\n",
    "\n",
    "#вытаскиватель категориальных фичей\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=False,dtype=np.bool)\n",
    "\n",
    "# используем встроенный питоновый парсер времени\n",
    "from dateutil import parser\n",
    "\n",
    "def preprocess_data(X_raw):\n",
    "\n",
    "    #распарсим время\n",
    "    datetimes = list(X_raw.due.apply(lambda x: parser.parse(x)))\n",
    "\n",
    "    #время дня от 0 до 1\n",
    "    rel_times = map(lambda dt: (dt.hour*60 + dt.minute)/(24.*60), datetimes)\n",
    "\n",
    "    #день недели\n",
    "    week_days = map( lambda x: x.isoweekday() , datetimes)\n",
    "\n",
    "    rel_times = np.array(rel_times)\n",
    "    week_days = np.array(week_days)\n",
    "    \n",
    "    is_holiday = map(lambda dt: (dt.day,dt.month) in holidays,\n",
    "                 datetimes)\n",
    "\n",
    "    dow_names = ['mon','tue','wed','thu','fri','sat','sun']\n",
    "    \n",
    "    city_names = [0, 1, 2, 3, 4, 5]\n",
    "    \n",
    "    data_dict = ( {'city_id':city_names[city_id+1], \n",
    "                   'f_class':f,\n",
    "                   's_class':(s if (pd.isnull(s)) else (str(f) + str(s))),\n",
    "                   't_class':(t if (pd.isnull(t)) else(str(f) + str(s) + str(t))),\n",
    "                   'day_of_week':dow_names[day_of_week-1]}\n",
    "                 \n",
    "            for (city_id,f,s,t),day_of_week in zip(X_raw[['city_id', \n",
    "                                                         'f_class',\n",
    "                                                         's_class',\n",
    "                                                         't_class']].values, week_days) )\n",
    "\n",
    "    \n",
    "    Xcat = vectorizer.fit_transform(data_dict)\n",
    "\n",
    "    other_features = [\"dist\",\"lat\",\"lon\"]\n",
    "    \n",
    "    Xreal = X_raw[other_features].values\n",
    "    \n",
    "    \n",
    "    Xfull = np.concatenate([\n",
    "            Xreal,\n",
    "            Xcat            \n",
    "        ],axis=1)\n",
    "    \n",
    "    Xfull = pd.DataFrame(Xfull,columns=other_features+vectorizer.feature_names_)\n",
    "    \n",
    "    Xfull[\"time_of_day_rel\"] = rel_times\n",
    "    Xfull[\"is_holiday\"] = is_holiday\n",
    "\n",
    "    \n",
    "    return Xfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = preprocess_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'dist', u'lat', u'lon', u'city_id', u'day_of_week=fri',\n",
       "       u'day_of_week=mon', u'day_of_week=sat', u'day_of_week=sun',\n",
       "       u'day_of_week=thu', u'day_of_week=tue', u'day_of_week=wed', u'f_class',\n",
       "       u'f_class=business', u'f_class=econom', u'f_class=vip', u's_class',\n",
       "       u's_class=businesseconom', u's_class=businessvip',\n",
       "       u's_class=econombusiness', u's_class=economvip', u's_class=vipbusiness',\n",
       "       u's_class=vipeconom', u't_class', u't_class=businesseconomvip',\n",
       "       u't_class=businessvipeconom', u't_class=econombusinessvip',\n",
       "       u't_class=economvipbusiness', u't_class=vipbusinesseconom',\n",
       "       u't_class=vipeconombusiness', u'time_of_day_rel', u'is_holiday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = data['burned'].values\n",
    "# X_NEW = X_and_test_copy.head(len(y))\n",
    "# TEST_NEW = X_and_test_copy[len(y):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_NEW_copy = X_NEW.copy()\n",
    "# TEST_NEW_copy = TEST_NEW.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print X_NEW_copy.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Также обучим более \"случайную\" версию RandomForest\n",
    "model = RandomForestClassifier(n_estimators=150,n_jobs=-1,min_samples_split=75,min_samples_leaf=20)\n",
    "\n",
    "# model.fit(Xtr,Ytr)\n",
    "model.fit(X_NEW, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,accuracy_score,precision_score,recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "for source_i, Xi,Yi in [\n",
    "                            [\"train\",Xtr,Ytr],\n",
    "                            [\"val\",Xval,Yval]\n",
    "                                ]:\n",
    "    \n",
    "    # Предскажем вероятность сгорания\n",
    "    Yi_pred_proba = model.predict_proba(Xi)[:,1]\n",
    "    \n",
    "    #Поделим предсказание на сгоревшие и не сгоревшие\n",
    "    Yi_pred_class = np.argsort(Yi_pred_proba) < 10000\n",
    "    \n",
    "    auc = roc_auc_score(Yi,Yi_pred_proba)\n",
    "    acc = accuracy_score(Yi,Yi_pred_class)\n",
    "    \n",
    "    print '%s: \\t AUC = %.5f \\t Accuracy = %.5f'%(source_i, auc, acc)\n",
    "    \n",
    "    fpr,tpr,_ = roc_curve(Yi,Yi_pred_proba)\n",
    "    \n",
    "    plt.plot(fpr,tpr,label = source_i)\n",
    "    \n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from datanight import plot_forest_feature_importances\n",
    "# plot_forest_feature_importances(model,X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from datanight import generate_submission\n",
    "# generate_submission(preprocess_data,model,\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Советы по улучшению модели:\n",
    "\n",
    "* Смотри глазами на данные - строй графики, исследуй аномалия \n",
    " * это может принести новые идеи и отбросить нежизнеспособные намного раньше \n",
    " * Туториал по библиотеке, в которой можно строить графики \n",
    "   * http://matplotlib.org/users/pyplot_tutorial.html\n",
    " * Ключевой вопрос самому себе - __\"От чего ещё может зависеть, сгорит ли заказ?\"__\n",
    "\n",
    "\n",
    "* Попробуй более точно настроить модель или выбрать другую\n",
    " * Random Forest с текущими параметрами можно улучшить\n",
    "   * Документация по нему - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    " * А можно использовать другие, более подходящие методы\n",
    "   * Документация по методам - http://scikit-learn.org/stable/supervised_learning.html\n",
    " * Наконец, модели можно комбинировать\n",
    "   * Например, усреднять с весами\n",
    "   * В итоге качество может быть лучше, чем у каждой модели по отдельности\n",
    " * Важно не увлечься - зачастую качественные изменения решения намного лучше подкручивания параметров\n",
    "\n",
    "\n",
    "* Подумай, какие ещё дополнительные данные можно провязать с выборкой? \n",
    " * насколько реально применить их за отведённое время?\n",
    "\n",
    "\n",
    "* __Главное__ - пытайся понять, дадут ли твои улучшения прирост на новых данных\n",
    " * Тестовая выборка находится по времени дальше, чем обучающая.\n",
    "   * Например, нельзя использовать номер дня в году, потому что мы обучаемся на выборке __ДО__ начала контрольной\n",
    " * Это не значит, что нужно отправлять миллион решений на проверку и выбирать лучшее - это приведёт к переобучению\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
